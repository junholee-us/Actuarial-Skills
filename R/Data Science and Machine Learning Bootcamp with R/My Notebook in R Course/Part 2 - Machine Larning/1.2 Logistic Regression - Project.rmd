---
title: "1.2 Logistic Regression - Project"
output: html_document
---
## Logistic Regression Project - Solutions
In this project we will be working with the UCI adult dataset. We will be attempting to predict if people in the data set belong in a certain class by salary, either making <=50k or >50k per year.

Typically most of your time is spent cleaning data, not running the few lines of code that build your model, this project will try to reflect that by showing different issues that may arise when cleaning data.


## Get the Data
Read in the adult_sal.csv file and set it to a data frame called adult.

```{r}
adult <- read.csv('adult_sal.csv')
```

Check the head of adult
```{r}
head(adult)
```

##Data Cleaning

Notice that we have a lot of columns that are cateogrical factors, however a lot of these columns have too many factors than may be necessary. In this data cleaning section we'll try to clean these columns up by reducing the number of factors.

You should notice the index has been repeated. Drop this column.

```{r}
library(dplyr)
adult <- select(adult,-X)
```

```{r}
print(str(adult))
```

```{r}
table(adult$type_employer)
```

```{r}
# Combine employer type
unemp <- function(job){
  job <- as.character(job) 
  if (job == 'Never-worked' | job =='Without-pay') {
    return('Unemployed')
  } else {
    return(job)
  }
}

adult$type_employer <- sapply(adult$type_employer,unemp)
table(adult$type_employer)
```

```{r}
group_emp <- function(job){
    if (job=='Local-gov' | job=='State-gov'){
        return('SL-gov')
    }else if (job=='Self-emp-inc' | job=='Self-emp-not-inc'){
        return('self-emp')
    }else{
        return(job)
    }
}

adult$type_employer <- sapply(adult$type_employer,group_emp)
table(adult$type_employer)
```

Marital Column
Use table() to look at the marital column
```{r}
table(adult$marital)
```
Reduce this to three groups:

Married
Not-Married
Never-Married

```{r}
group_marital <- function(mar){
    mar <- as.character(mar)
    
    # Not-Married
    if (mar=='Separated' | mar=='Divorced' | mar=='Widowed'){
        return('Not-Married')
    
    # Never-Married   
    }else if(mar=='Never-married'){
        return(mar)
    
     #Married
    }else{
        return('Married')
    }
}

adult$marital <- sapply(adult$marital,group_marital)
table(adult$marital)
```

Country Column
Check the country column using table()
```{r}
table(adult$country)
```

```{r}
levels(adult$country)
```


```{r}
Asia <- c('China','Hong','India','Iran','Cambodia','Japan', 'Laos' ,
          'Philippines' ,'Vietnam' ,'Taiwan', 'Thailand')

North.America <- c('Canada','United-States','Puerto-Rico' )

Europe <- c('England' ,'France', 'Germany' ,'Greece','Holand-Netherlands','Hungary',
            'Ireland','Italy','Poland','Portugal','Scotland','Yugoslavia')

Latin.and.South.America <- c('Columbia','Cuba','Dominican-Republic','Ecuador',
                             'El-Salvador','Guatemala','Haiti','Honduras',
                             'Mexico','Nicaragua','Outlying-US(Guam-USVI-etc)','Peru',
                            'Jamaica','Trinadad&Tobago')
Other <- c('South')
```

```{r}
group_country <- function(ctry){
    if (ctry %in% Asia){
        return('Asia')
    }else if (ctry %in% North.America){
        return('North.America')
    }else if (ctry %in% Europe){
        return('Europe')
    }else if (ctry %in% Latin.and.South.America){
        return('Latin.and.South.America')
    }else{
        return('Other')      
    }
}

adult$country <- sapply(adult$country,group_country)
table(adult$country)
```

## Missing Data
Notice how we have data that is missing.

```{r}
# HANDLING MISSING DATA
library(Amelia)
```
Convert any cell with a '?' or a ' ?' value to a NA value. Hint: is.na() may be useful here or you can also use brackets with a conditional statement. Refer to the solutions if you can't figure this step out.

```{r}
adult[adult == '?'] <- NA
```

```{r}
# FACTOR
adult$type_employer <- sapply(adult$type_employer,factor)
adult$country <- sapply(adult$country,factor)
adult$marital <- sapply(adult$marital,factor)
```

```{r}
missmap(adult,y.at=c(1),y.labels = c(''),col=c('yellow','black'))
```

```{r}
# DROP MISSING DATA
adult <- na.omit(adult)
```

```{r}
missmap(adult,y.at=c(1),y.labels = c(''),col=c('yellow','black'))
```

## EDA
Although we've cleaned the data, we still have explored it using visualization.

Use ggplot2 to create a histogram of ages, colored by income.
```{r}
library(ggplot2)
library(dplyr)
ggplot(adult,aes(age)) + geom_histogram(aes(fill=income),color='black',binwidth=1) + theme_bw()
```

Plot a histogram of hours worked per week
```{r}
ggplot(adult,aes(hr_per_week)) + geom_histogram() + theme_bw()
```

```{r}
adult <- rename(adult, region = country)
print(head(adult))
```

Create a barplot of region with the fill color defined by income class. Optional: Figure out how rotate the x axis text for readability
```{r}
ggplot(adult,aes(region)) + geom_bar(aes(fill=income),color='black') + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Building a Model
Now it's time to build a model to classify people into two groups: Above or Below 50k in Salary.

## Logistic Regression
Logistic Regression is a type of classification model. In classification models, we attempt to predict the outcome of categorical dependent variables, using one or more independent variables. The independent variables can be either categorical or numerical.

Logistic regression is based on the logistic function, which always takes values between 0 and 1. Replacing the dependent variable of the logistic function with a linear combination of dependent variables we intend to use for regression, we arrive at the formula for logistic regression.

Take a quick look at the head() of adult to make sure we have a good overview before going into building the model!
```{r}
head(adult)
```

## Train Test Split
Split the data into a train and test set using the caTools library as done in previous lectures. Reference previous solutions notebooks if you need a refresher.
```{r}
# Import Library
library(caTools)

# Set a random see so your "random" results are the same as this notebook
set.seed(101) 

# Split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(adult$income, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE

# Training Data
train = subset(adult, sample == TRUE)

# Testing Data
test = subset(adult, sample == FALSE)
```

## Training the Model
Explore the glm() function with help(glm). Read through the documentation.
Use all the features to train a glm() model on the training data set, pass the argument family=binomial(logit) into the glm function.

```{r}
model = glm(income ~ ., family = binomial(logit), data = train)
```

```{r}
summary(model)
```

We have still a lot of features! Some important, some not so much. R comes with an awesome function called step(). The step() function iteratively tries to remove predictor variables from the model in an attempt to delete variables that do not significantly add to the fit. How does it do this? It uses AIC. Read the wikipedia page for AIC if you want to further understand this, you can also check out help(step). This level of statistics is outside the scope of this project assignment so let's keep moving along

## Choose a model by AIC in a Stepwise Algorithm

Use new.model <- step(your.model.name) to use the step() function to create a new model.
```{r}
new.step.model <- step(model)
```

```{r}
test$predicted.income = predict(model, newdata=test, type="response")

table(test$income, test$predicted.income > 0.5)
```

What was the accuracy of our model?
```{r}
# (TRUE FALSE + TRUE TRUE) / (OVERALL)
(6372+1423)/(6372+1423+548+872)
```

Calculate other measures of performance like, recall or precision.

```{r}
#recall
6732/(6372+548)
```

```{r}
#precision
6732/(6372+872)
```